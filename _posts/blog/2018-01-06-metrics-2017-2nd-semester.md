---
  layout: "post"
  title: "Learning Data Science. Some metrics"
  excerpt: "2017 my last six months on self-learning metrics. Where I put the hours and how many."
  categories: blog
  tags: [data science, changing career, job hunting, self-learning, R, python, procastination, accountability, statistics, DataCamp, udacity, udemy, blogging]
  author: rachel
  comments: true
  share: true
  image:
    feature: banner2.jpg
    credit:
    creditlink:
  date: "2018-01-06 11:33"
  modified: "2018-01-06 11:33"
---


2017 has been a fantastic year for me concerning data science. I did learn so many things that I am astonished when I see some of my data.
I started collecting data of the time I have spent learning different concepts. The following tree chart corresponds only to the last six months of 2017 because it was then when I started my monitoring journey.

The idea at the beginning was due to my willingness to learn different courses and subjects at the same time. Up to that date, I realised I could learn quickly new things and concepts, but what it was tough was keeping that knowledge with the pass of the time if I was not using that new tool I have learned.

That was important to me! As I did want to be able to put on my resume my new skills, and at the same time, I did want to have it always fresh in my mind to pass technical interviews.
So, I did change my learning strategy. I started learning fewer hours every day on each subject as well as many topics at the same time. Soon, I realised that I needed to track what I was doing to being able to balance everything.

The good draws of that strategy are that I was accountable to myself in a much more structured way. I could as well balance my learning hours during the week. That allowed to have a half day off or a full day and being aware that I have to compensate it during the weekend.

I only tracked efficient hours. That was important an important point for me. All hours are real learning hours: coding, reading, watching videos, etc. Not a single minute of procrastination was recorded. My average per week was 32 hours, and I did have a maximum of 58 hours and a minimum of 7 hours in a week that I was sick.

This is the 2nd semester of 2017 summary concerning Data Science (I also did study other things on the way):

  ![2017 second semester summary]({{site.url}}/images/graphs/2017learning.png){: .pull-right}

And in a table,

Concept |	hours
 :---  |  ---:
**Udacity** |	405
**Blog**	|116
**Udemy**|111
**DataCamp**	|106
**Projects on R**	|58
**Coursera**|	48
**Kaggle**|38
**Reading**	|37
**Linkedin profile and Job Hunting**	| 32
**Interview Preparation**	| 24
**edx**	| 22
**Linkedin Learning** |	9
**Git & GitHub** |	6
**fast.ai Deep Learning**|	2
**Domestika**|	2

[Udacity][d1b4e3c1], by far, is the **big winner** if that was a competition.
In this platform, I did study two nano degrees (Deep Learning Foundations and Artificial Intelligence) as well as the first phase of the [Google Developer Challenge Scholarship][11544b19] (Front-End). But I also did many free courses: Statistics, Git&Github, Machine Learning, Algebra, A/B Testing,...

  [d1b4e3c1]: www.Udacity.com "Udacity"
  [11544b19]: ({{site.url}}/_posts/blog/2017-10-31-Google-developer-challenge.md "Google Developer Challenge Scholarship"

By far, it has been the most significant discovery of this year. Its credentials have led me to a considerable improvement in the success on getting job interviews.  It is important to show confidence in your knowledge for passing interviews, but you need a good education and experience in the resume to get you to that stage.

Luckily for us, the [European Commission has rewarded its contribution to teaching new digital skills](https://blog.udacity.com/2017/12/european-commission-digital-skills-award.html),  highlighting it as a standing out learning school for IT skills.

By far the most hours on this platform were due to the Nanodegrees ([Artificial Intelligence]({{site.url}}/_posts/articles/2017-10-30-AI-Nanodegree-Review-first-term.md)
 with nearly 190h And Deep Learning with 150h)

The **silver** medal is for Udemy (111 h), within its cheap courses I discovered several from Jose Portilla's or Kirill Eremenko's. Both are very good communicators and I did use their courses to reinforce my learning from a topic. Most of the courses provide good resources: Jupyter notebooks as well as projects to code, that serve as good companions when you need help .
I already followed [Kirill Podcast](https://www.superdatascience.com/podcast/) since his very beginnings with it.
The topics I put on more hours at [Udemy][7c2a13da] were, by far, Python (37h) and Spark (27h).

The **bronze** medal is for this blog. I did consider its construction as learning Data Science because it does incorporate GitHub (hosting is in it), building my portfolio, as well as reading and writing about Data Science. The time consumed is around 109h, and I hope that is the topic that grows more in 2018. My longest journeys were due to it. I build and rebuild the site a lot of times until I got comfortable with it.

I have to give a special mention to [DataCamp][bfb475e2]  (105h). This is a membership site in which I did spend, consistently, some of my time every single day for the last months. It helps me to discover new packages and functionalities for both languages R and Python. I did study all of the Career Tracks and Skill Tracks available and I plan to visit every day in order to keep me update.


  [7c2a13da]: https://www.udemy.com/courses/ "Udemy"
  [bfb475e2]: https://www.datacamp.com/ "DataCamp"

I do plan to continue tracking my time in this 2018. So I can see my evolution and dedication in the field of data Science.

Let's learn a lot (more) in 2018!!
